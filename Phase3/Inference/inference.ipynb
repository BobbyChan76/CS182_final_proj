{"cells":[{"cell_type":"markdown","metadata":{"id":"rBOju_k1iRrq"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"fhelsiV5UvVx"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers\u003c0.19,\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors\u003e=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etransformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etransformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2023.11.17)\n","Collecting datasets\n","  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow\u003e=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting pyarrow-hotfix (from datasets)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Collecting dill\u003c0.3.8,\u003e=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests\u003e=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm\u003e=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]\u003c=2023.10.0,\u003e=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub\u003e=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (23.1.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (6.0.4)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.9.3)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.4.0)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.3.1)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (4.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.18.0-\u003edatasets) (3.13.1)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.18.0-\u003edatasets) (4.5.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2023.11.17)\n","Requirement already satisfied: python-dateutil\u003e=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2023.3.post1)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.1-\u003epandas-\u003edatasets) (1.16.0)\n","Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n","Successfully installed datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n","Collecting peft\n","  Downloading peft-0.7.0-py3-none-any.whl (168 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.23.5)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch\u003e=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu118)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.35.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.1)\n","Collecting accelerate\u003e=0.21.0 (from peft)\n","  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.1)\n","Requirement already satisfied: huggingface-hub\u003e=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.19.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.17.0-\u003epeft) (3.13.1)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.17.0-\u003epeft) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.17.0-\u003epeft) (2.31.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.17.0-\u003epeft) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epeft) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epeft) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epeft) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epeft) (2.1.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers-\u003epeft) (2023.6.3)\n","Requirement already satisfied: tokenizers\u003c0.19,\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers-\u003epeft) (0.15.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.13.0-\u003epeft) (2.1.3)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.17.0-\u003epeft) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.17.0-\u003epeft) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.17.0-\u003epeft) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.17.0-\u003epeft) (2023.11.17)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.13.0-\u003epeft) (1.3.0)\n","Installing collected packages: accelerate, peft\n","Successfully installed accelerate-0.25.0 peft-0.7.0\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.41.3-py3-none-any.whl (92.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.41.3\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}],"source":["%pip install transformers\n","%pip install datasets\n","%pip install peft\n","%pip install bitsandbytes\n","%pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Y8tBNu_xUx4s"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import torch\n","from tqdm import tqdm\n","from datasets import Dataset\n","from datasets import load_dataset, concatenate_datasets\n","from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from peft import AutoPeftModelForCausalLM\n","from transformers import pipeline\n","from transformers import BitsAndBytesConfig\n","import sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9U_eKWj9Uhko"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"omHBV6EuUlOg"},"outputs":[],"source":["%cd drive/MyDrive/CS\\ 182\\ Final\\ Project/Phase\\ 3"]},{"cell_type":"markdown","metadata":{"id":"KJ7mCJ75iUbN"},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ETaMMWyOXR0Q"},"outputs":[],"source":["def add_label_train(example):\n","  example['dataset'] = 'train'\n","  return example\n","\n","def add_label_val(example):\n","  example['dataset'] = 'val'\n","  return example\n","\n","dataset_path = \"qwedsacf/grade-school-math-instructions\"\n","data = load_dataset(dataset_path, split=\"train\")\n","data = data.train_test_split(test_size=0.15, seed=123)\n","training_data, validation_data = data['train'], data['test']\n","\n","training_data = training_data.train_test_split(test_size=500, seed=123)\n","validation_data = validation_data.train_test_split(test_size=500, seed=123)\n","\n","training_data_humaneval = data['train'].train_test_split(test_size=50, seed=321)\n","validation_data_humaneval = data['test'].train_test_split(test_size=50, seed=321)\n","\n","test_data = concatenate_datasets([training_data['test'].map(add_label_train),\n","                                  validation_data['test'].map(add_label_val)])\n","\n","test_data_humaneval = concatenate_datasets([training_data_humaneval['test'].map(add_label_train),\n","                                  validation_data_humaneval['test'].map(add_label_val)])\n","\n","test_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csfrcmj23uKO"},"outputs":[],"source":["# preconditioning = 'You are a helpful assistant. Given a word problem, you need to break it down into steps and solve them step-by-step.'\n","# def preprocess(example):\n","#   example['text'] = \"\u003cs\u003e[INST] \u003c\u003cSYS\u003e\u003e\"+preconditioning+\"\u003c\u003c/SYS\u003e\u003e\"+example['INSTRUCTION']+\"[/INST]\"+example[\"RESPONSE\"]+\"\u003c/s\u003e\"\n","#   return example\n","\n","# test_data = test_data.map(preprocess)"]},{"cell_type":"markdown","metadata":{"id":"loWKLTqejQkp"},"source":["## Test pipeline"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1701898100697,"user":{"displayName":"Mihran Miroyan","userId":"16574442679150837175"},"user_tz":480},"id":"OkmGY30NnYPn"},"outputs":[],"source":["def get_test_ppl(model, tokenizer, dataset, exp_name, base_model=False, device='cuda'):\n","\n","  nlls = []\n","  responses = []\n","\n","  for example in tqdm(dataset):\n","    instruction = example['INSTRUCTION']\n","    response = example['RESPONSE']\n","    preconditioning = 'You are a helpful assistant. Given a word problem, you need to break it down into steps and solve them step-by-step.'\n","\n","    if not base_model:\n","      instruction = \"\u003cs\u003e[INST] \u003c\u003cSYS\u003e\u003e\"+preconditioning+\"\u003c\u003c/SYS\u003e\u003e\"+instruction+\"[/INST]\"\n","      full = instruction + response+\"\u003c/s\u003e\"\n","    else:\n","      instruction = preconditioning + \" \" + instruction\n","      full = instruction + \" \" + response\n","\n","    instruction_encoding_length = tokenizer(instruction, return_tensors=\"pt\").input_ids.shape[1]\n","    full_encoding = tokenizer(full, return_tensors='pt')\n","    input_ids = full_encoding.input_ids\n","    target_ids = input_ids.clone()\n","    target_ids[:, :instruction_encoding_length] = -100\n","\n","    with torch.no_grad():\n","      output = model(input_ids.to(device), labels=target_ids.to(device))\n","      nlls.append(output.loss.item())\n","\n","  df = pd.DataFrame(dataset)\n","  df['nll'] = nlls\n","  df['ppl'] = torch.exp(torch.tensor(nlls))\n","  df.to_csv(f'./inference_results/{exp_name}.csv', index=False)\n","  return df\n","\n","\n","def get_test_responses(model, tokenizer, dataset, exp_name, base_model=False, device='cuda'):\n","\n","  responses = []\n","\n","  for example in tqdm(dataset):\n","    instruction = example['INSTRUCTION']\n","    preconditioning = 'You are a helpful assistant. Given a word problem, you need to break it down into steps and solve them step-by-step.'\n","\n","    if not base_model:\n","      instruction = \"\u003cs\u003e[INST] \u003c\u003cSYS\u003e\u003e\"+preconditioning+\"\u003c\u003c/SYS\u003e\u003e\"+instruction+\"[/INST]\"\n","    else:\n","      instruction = preconditioning + \" \" + instruction\n","\n","    with torch.no_grad():\n","\n","      input_ids = tokenizer(instruction, return_tensors=\"pt\").input_ids.to(device)\n","      instruction_encoding_length = input_ids.shape[1]\n","      generated_output = model.generate(\n","          input_ids=input_ids, max_new_tokens=50, pad_token_id=tokenizer.eos_token_id\n","      )\n","      generated_text = tokenizer.decode(generated_output[0][instruction_encoding_length:])\n","      responses.append(generated_text)\n","\n","  df = pd.DataFrame(dataset)\n","  df['responses'] = responses\n","  df.to_csv(f'./inference_results/{exp_name}.csv', index=False)\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_qzUOvjnKL9"},"outputs":[],"source":["model_path = \"./train_results/gpt2-xl-r8-a32/gpt2-xl-problem-solver\"\n","base_model_path = \"gpt2-xl\"\n","# base_model_path = 'openlm-research/open_llama_3b_v2'\n","\n","tokenizer = AutoTokenizer.from_pretrained(base_model_path, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\"\n","\n","quant_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16,\n","    bnb_4bit_use_double_quant=False\n",")\n","\n","# del model\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_path,\n","    quantization_config=quant_config,\n","    device_map={\"\": 0}\n",")\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fnT47jsaxR-J"},"outputs":[],"source":["results_ppl = get_test_ppl(model, tokenizer, test_data, 'gpt2-r8-a32-ppl', base_model=False, device=\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":571180,"status":"ok","timestamp":1701885292761,"user":{"displayName":"Mihran Miroyan","userId":"02360843806113047461"},"user_tz":480},"id":"GFGbvH3boDT_","outputId":"4e81894c-dcfd-4a36-9497-07d4f5ebac43"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [09:31\u003c00:00,  5.71s/it]\n"]}],"source":["# results_responses = get_test_responses(model, tokenizer, test_data_humaneval, 'gpt2-r64-a32-responses', base_model=False, device=\"cuda\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["rBOju_k1iRrq","KJ7mCJ75iUbN"],"machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}